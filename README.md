# FAST KAFKALCHEMY

## Описание

Это проект, построенный с использованием FastAPI, PostgreSQL, Kafka и Docker. 

Цель проекта — наработка опыта работы с перечисленными выше технологиями.

Проект включает в себя:

    FastAPI для создания REST API.
    PostgreSQL в качестве базы данных.
    Kafka в качестве брокера сообщений
    Docker для контейнеризации и упрощения запуска проекта.

## Требования

Для корректной работы проекта убедитесь, что у вас установлены следующие инструменты:

    Docker и Docker compose
    Python 3.10+ — для запуска FastAPI приложения (если не используется контейнер).
    PostgreSQL (если работаете вне контейнера).
    Kafka (если работаете вне контейнера).

## Запуск проекта с использованием Docker Compose

1) Клонируйте репозиторий и перейдите в него:

```commandline
git clone git@github.com:niceguy135/fast_kafkalchemy.git; cd fast_kafkalchemy
```

2) Постройте и запустите контейнеры через Docker Compose:

```commandline
docker-compose up --build
```

3) После того, как все сервисы были успешно запущены, выполните на хостовой машине команду:
```commandline
docker exec fastapi_rest1 bash prestart.sh
```

Данная команда проверит работоспособность базы данных,
применит последнюю миграцию и создаст 10 тестовых записей в таблице ``applications`` БД

4) После выполнения этой команды Docker Compose создаст и запустит следующие контейнеры:

    FastAPI приложение, доступное по адресу http://localhost:8000
    PostgreSQL контейнер с базой данных, доступный на порту 5432
    Kafka брокер, доступный с хостовой машины на порту 9092

5) Для остановки и удаления контейнеров выполните:

```commandline
docker-compose down
```

## API

    GET /applications/ - Получить список заявок от всех пользователей или от конкретного пользователя.
    POST /applications/ - Создать новую заявку от пользователя

Также есть возможность перейти в браузере на ``/docs``, где будет открыта Swagger API документация, 
в которой можно удобно протестировать работоспособность API

## Кратко про сервисы и фичи

### Валидация и пагинация через Pydantic

В этом проекте активно используется возможность валидировать данные с помощью DTO схем Pydantic

Также используется библиотека ``fastapi_pagination`` для пагинации запрашиваемых данных с сервера

### Kafka

Проект использует Kafka в качестве брокера сообщений. 
Используется библиотека ``aiokafka`` для асинхронной передачи сообщений в броке

В данной версии проекта в Kafka создается топик ``new_application``, куда отправляются данные
о новом созданном запросе от пользователя.

Чтобы и посмотреть выв можете выполнить на хостовой машине следующую команду:
```commandline
kcat -b 127.0.0.1:9092 -t new_application
```

Перед этим соответсвенно установите саму утилиту ``kcat``:
```commandline
sudo apt install kcat
```

### Логирование

Проект использует стандартное логирование Python. Логи можно будет увидеть в консоли при запуске проекта через Docker Compose.

### Тесты:

Были написаны unit-тесты для проверки коректности работы бэкенда.
Чтобы их запустить, разверните приложение по инструкции выше и выполните на хостовой машине команду:
```commandline
docker exec fastapi_rest1 pytest
```

### Примечания

Для более детальной настройки подключения к базе данных и Kafka можно изменить настройки в rest_service/app/.env и соответствующих конфигурационных файлах.
